---
title: “it has been argued that current chatbots may pose a risk of amplifying delusional
  thinking in vulnerable users, due to their tendency to sycophantic and overly validating
  behaviour”
date: '2025-12-09'
linkTitle: https://statmodeling.stat.columbia.edu/2025/12/09/it-has-been-argued-that-current-chatbots-may-pose-a-risk-of-amplifying-delusional-thinking-in-vulnerable-users-due-to-their-tendency-to-sycophantic-and-overly-validating-behaviour/
source: Statistical Modeling, Causal Inference, and Social Science
description: This is Jessica. The area of AI/ML research dubbed “safety” includes
  investigating LLMs’ ability to intentionally mislead people, for example by performing
  worse on benchmarks when they know they are being tested, or withholding information
  when prompted. With this come &#8230; <a href="https://statmodeling.stat.columbia.edu/2025/12/09/it-has-been-argued-that-current-chatbots-may-pose-a-risk-of-amplifying-delusional-thinking-in-vulnerable-users-due-to-their-tendency-to-sycophantic-and-overly-validating-behaviour/">Continue
  reading <span class="meta-nav">&#8594;</span></a> ...
disable_comments: true
---
This is Jessica. The area of AI/ML research dubbed “safety” includes investigating LLMs’ ability to intentionally mislead people, for example by performing worse on benchmarks when they know they are being tested, or withholding information when prompted. With this come &#8230; <a href="https://statmodeling.stat.columbia.edu/2025/12/09/it-has-been-argued-that-current-chatbots-may-pose-a-risk-of-amplifying-delusional-thinking-in-vulnerable-users-due-to-their-tendency-to-sycophantic-and-overly-validating-behaviour/">Continue reading <span class="meta-nav">&#8594;</span></a> ...