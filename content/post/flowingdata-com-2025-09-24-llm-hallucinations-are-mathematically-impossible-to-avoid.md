---
title: LLM “hallucinations” are mathematically impossible to avoid
date: '2025-09-24'
linkTitle: https://flowingdata.com/2025/09/24/llm-hallucinations-are-mathematically-impossible-to-avoid/
source: FlowingData
description: From Gyana Swain for Computerworld on how &#8220;hallucinations&#8221;
  a.k.a. computer errors are inevitable&#8230;<p><strong>Tags:</strong> <a href="https://flowingdata.com/tag/computerworld/"
  rel="tag">Computerworld</a>, <a href="https://flowingdata.com/tag/error/" rel="tag">error</a>,
  <a href="https://flowingdata.com/tag/openai/" rel="tag">OpenAI</a>, <a href="https://flowingdata.com/tag/uncertainty/"
  rel="tag">uncertainty</a></p> ...
disable_comments: true
---
From Gyana Swain for Computerworld on how &#8220;hallucinations&#8221; a.k.a. computer errors are inevitable&#8230;<p><strong>Tags:</strong> <a href="https://flowingdata.com/tag/computerworld/" rel="tag">Computerworld</a>, <a href="https://flowingdata.com/tag/error/" rel="tag">error</a>, <a href="https://flowingdata.com/tag/openai/" rel="tag">OpenAI</a>, <a href="https://flowingdata.com/tag/uncertainty/" rel="tag">uncertainty</a></p> ...